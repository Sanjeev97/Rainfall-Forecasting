{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2092068,"sourceType":"datasetVersion","datasetId":539693}],"dockerImageVersionId":29926,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NOWCASTING RADAR RAINMAP","metadata":{}},{"cell_type":"markdown","source":"Original version by Gabriel Colas : https://www.kaggle.com/code/gabrielcolas/radar-nowcasting\n\n**/!\\ To use it correctly on Kaggle, choose a GPU accelerator, and switch Internet on in the options**","metadata":{}},{"cell_type":"markdown","source":"The goal of this project is to use Radar Data from meteonet as an image and to predict the movement of a rainmap radar using deep learning. <br>\nIn the Meteonet data, for each radar data type, you will find one archive per month, each one sliced in periods of 10 or 11 days (each month is separated in 3 files). <br> For this notebook we will forecast one hour data and use a 15 minuts step. <br> <br> So first our goal is to process those raw data and get in the order: <br> \n* Pick data for a 15 minuts step\n* Sequence of 6 rainmap for learning + 1 rainmap as label\n* 256 * 256 map\n\n* Repeat predict for 2 more predictions images by adding previous predictions","metadata":{}},{"cell_type":"markdown","source":"![](https://weatheregg.com/wp-content/uploads/2018/01/doppler-radar-map-weathergov.png)","metadata":{}},{"cell_type":"code","source":"# IMPORT THE LIBRARIES\nimport os\nimport numpy as np\nfrom datetime import datetime, timedelta\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.callbacks import TensorBoard\nfrom keras.callbacks import ModelCheckpoint\n# from keras.optimizers import *\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2025-03-24T16:41:30.269794Z","iopub.execute_input":"2025-03-24T16:41:30.270052Z","iopub.status.idle":"2025-03-24T16:41:36.127874Z","shell.execute_reply.started":"2025-03-24T16:41:30.270025Z","shell.execute_reply":"2025-03-24T16:41:36.126837Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LOCATION OF THE TRAINING DATA\ndirectory = '/kaggle/input/meteonet/'\ndirectory_save = '/kaggle/working/'\nzone = \"NW\"","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:41:41.414558Z","iopub.execute_input":"2025-03-24T16:41:41.414934Z","iopub.status.idle":"2025-03-24T16:41:41.419672Z","shell.execute_reply.started":"2025-03-24T16:41:41.414899Z","shell.execute_reply":"2025-03-24T16:41:41.418233Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fname_coords = os.path.join(directory,'Radar_coords/Radar_coords',f'radar_coords_{zone}.npz')\ncoords = np.load(fname_coords, allow_pickle=True)\n\n# Updated version : already centered\nlat = coords['lats']\nlon = coords['lons']","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:41:44.612271Z","iopub.execute_input":"2025-03-24T16:41:44.612607Z","iopub.status.idle":"2025-03-24T16:41:44.656122Z","shell.execute_reply.started":"2025-03-24T16:41:44.612578Z","shell.execute_reply":"2025-03-24T16:41:44.655023Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3> LOAD THE USEFULL FUNCTIONS FOR ANALYSIS </h3>","metadata":{}},{"cell_type":"code","source":"# LOAD ANY RAINFALL RADAR PICKLE\ndef load_fichier(year,part_month,month):\n    directory = '/kaggle/input/meteonet/'\n    zone = \"NW\"\n    fname = os.path.join(directory, f'{zone}_rainfall_{str(year)}/{zone}_rainfall_{str(year)}/rainfall-{zone}-{str(year)}-{str(month).zfill(2)}/rainfall-{zone}-{str(year)}-{str(month).zfill(2)}/rainfall_{zone}_{str(year)}_{str(month).zfill(2)}.{str(part_month)}.npz')\n    pickle = np.load(fname, allow_pickle=True)\n    return pickle","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:42:02.490542Z","iopub.execute_input":"2025-03-24T16:42:02.490990Z","iopub.status.idle":"2025-03-24T16:42:02.496999Z","shell.execute_reply.started":"2025-03-24T16:42:02.490949Z","shell.execute_reply":"2025-03-24T16:42:02.495821Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# convert a date to an index, corresponding to an initial date\ndef indice_date(date_init, date_value):    \n    Diff_year = date_value.year - date_init.year\n    Diff_Month = date_value.month - date_init.month\n    Diff_Day = date_value.day - date_init.day\n    Diff_Hour = date_value.hour - date_init.hour\n    Diff_Minute = date_value.minute - date_init.minute    \n    indice = Diff_Day*24*12 + Diff_Hour*12 + Diff_Minute/Step_data\n    \n    return {'Diff_year' : Diff_year , 'Diff_Month' : Diff_Month, 'indice' : indice}\n\n\n# Convert the given date of the pickle to the missing index.\ndef indice_miss_date(pickle):\n    indice_tab= np.zeros(pickle['miss_dates'].shape[0],dtype=int)\n    print(\"This is the missing date in the data: \",pickle['miss_dates'])\n    \n    compteur = 0\n    for miss_date in pickle['miss_dates']:\n        print('miss_date : ', miss_date)\n        dico_i = indice_date(pickle['dates'][0], miss_date)\n        indice_abs = int(dico_i['indice']) / dico_i['indice']\n        # We raise error because for now we don't handle that kind of situation\n        if dico_i['Diff_year'] != 0 or dico_i['Diff_Month'] != 0:\n            raise NameError('There is a difference in month or year !')\n        if indice_abs != 1:\n            raise NameError('Indice is not a integer')\n        else:\n            indice_tab[compteur] = int(dico_i['indice'])\n        compteur += 1\n    return indice_tab\n\n\n# cut the input data by the step we have consider\ndef cut_timestep(pickle, Step_minute):    \n    print(\"We make a step every \", Step, \"indices\")\n    Val_selec = np.arange(0,len(pickle['dates']), Step) # Every  'Step' index corresponding to 'Step_minute' minutes\n    return pickle['data'][Val_selec,:,:], pickle['dates'][Val_selec]\n\n\n# If Missing values.\ndef cut_timestep_miss(pickle,Echeance_minute,Step_minute) :\n    \n    Qinit = (Step * Tot) - Step\n    Q1= Step * Tot\n  \n    indice_tab = indice_miss_date(pickle) # LOAD indice_miss_date function to get the missing indices \n    \n    Tab_index = []    \n    valeur_init = 0\n    \n    # last theorical index if no missing datas between begin and end times\n    last_index = int(indice_date(pickle[\"dates\"][0], pickle['dates'][-1])['indice'])\n    \n    for indice in indice_tab:\n       \n        Sequence = np.arange(valeur_init , indice , Step , dtype=int)\n        Tab_index.append(Sequence[ : Tot *(len(Sequence) // Tot)])\n    \n        # We can begin to find the next sequence just after the next index\n        # which must be a multiple of the Step\n        i = 0\n        while (((indice + i + 1) % Step) > 0) and (indice + i + 1 <= last_index):\n            i += 1\n        valeur_init = indice + i + 1   \n       \n\n    Sequence = np.arange(valeur_init , last_index + 1 , Step , dtype = int)\n    Tab_index.append(Sequence[: Tot * (len(Sequence) // Tot)])\n\n    return Tab_index\n","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:42:22.625503Z","iopub.execute_input":"2025-03-24T16:42:22.625879Z","iopub.status.idle":"2025-03-24T16:42:22.644490Z","shell.execute_reply.started":"2025-03-24T16:42:22.625844Z","shell.execute_reply":"2025-03-24T16:42:22.643362Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cut_data_and_coord(data, Pixel, lat,lon, lat_edge = 49.5, lon_edge = -2.5):    \n    lat_only=lat[:,1]\n    lon_only=lon[1,:]\n    Temp_lat = np.where(lat_only < lat_edge)\n    Temp_lon = np.where(lon_only < lon_edge)\n    Lat_cut_index = Temp_lat[0][:Pixel]\n    Lon_cut_index = Temp_lon[0][:Pixel]\n    data_cut = data[:,Lat_cut_index]\n    data_cut= data_cut[:,:,Lon_cut_index]\n    return data_cut\n\ndef cut_timestep_miss2(pickle, Echeance_minute, Step_minute):\n    Tab = cut_timestep_miss(pickle, Echeance_minute, Step_minute)\n    # all the valid sequence indexes\n    Tab_tot = np.concatenate(Tab)\n    \n    # but we have to make a conversion for missing dates indexes\n    \n    time_init = pickle['dates'][0]\n    time_final = pickle['dates'][-1]\n    \n    # list all the theorical times if there was no missing data\n    liste_t = np.arange(time_init, time_final + timedelta(minutes=Step_data), timedelta(minutes = Step_data)).astype(datetime)\n   \n    Tab_tot2 = np.empty(len(Tab_tot), dtype = int)\n    \n    # search the indexes of the pickle dataset corresponding with the indexes of the Tab_tot\n    for i, indice in enumerate(Tab_tot):\n        time_indice = time_init + indice * timedelta(minutes = Step_data)\n        Tab_tot2[i] = np.where(pickle['dates'] == time_indice)[0][0]\n        \n    \n    return pickle['data'][Tab_tot2, :, :], pickle['dates'][Tab_tot2]\n    # it's possible to make another conversion method by just shifting indexes by one step every missing index\n    ","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:42:40.588214Z","iopub.execute_input":"2025-03-24T16:42:40.588575Z","iopub.status.idle":"2025-03-24T16:42:40.600172Z","shell.execute_reply.started":"2025-03-24T16:42:40.588540Z","shell.execute_reply":"2025-03-24T16:42:40.598773Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def XYTRAIN(data_process):\n    X_Train = np.zeros((0, Pixel, Pixel, Entrainement))\n    Y_Train = np.zeros((0, Pixel, Pixel, Prediction))\n    DATA_X = np.zeros((1, Pixel, Pixel, Entrainement))\n    DATA_Y = np.zeros((1, Pixel, Pixel,Prediction))\n    pas_X = 0\n    pas_Y = Entrainement - 1\n    print(\"Valeur max:\", int(data_process.shape[0] / Tot) )\n    for globale in range(int(data_process.shape[0] / Tot)):\n        for X in range(1, Entrainement + 1):\n            DATA_X[0, :, :, X - 1] = data_process[pas_X + X - 1, :, :]\n        for Y in range(1, Prediction + 1):\n            DATA_Y[0, :, :, Y-1] = data_process[pas_Y + Y, :, :]\n        pas_X += Tot\n        pas_Y += Tot\n        X_Train = np.append(X_Train, DATA_X, axis = 0)\n        Y_Train = np.append(Y_Train, DATA_Y, axis = 0)\n        DATA_X = np.zeros((1, Pixel, Pixel, Entrainement))\n        DATA_Y = np.zeros((1, Pixel, Pixel, Prediction))\n    return X_Train, Y_Train","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:42:45.527078Z","iopub.execute_input":"2025-03-24T16:42:45.527430Z","iopub.status.idle":"2025-03-24T16:42:45.538313Z","shell.execute_reply.started":"2025-03-24T16:42:45.527400Z","shell.execute_reply":"2025-03-24T16:42:45.537218Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def COUNT_RAIN_SITUATION(X_TRAIN, Y_TRAIN, rain_limit):\n    Count_X = 0\n    Count_Y = 0\n    Tab_delete = []\n    Count = 0\n    for X in X_TRAIN:\n        Temp_x = np.count_nonzero(X > rain_limit)\n        if (Temp_x <= 200):\n            Count_X += 1\n            Tab_delete.append(Count)\n        Count += 1\n        \n    for Y in Y_TRAIN:\n        Temp_y = np.count_nonzero(Y > rain_limit)\n        if Temp_y <= 200:\n            Count_Y += 1\n            \n    X_TRAIN = np.delete(X_TRAIN, Tab_delete,axis = 0)\n    Y_TRAIN = np.delete(Y_TRAIN, Tab_delete,axis = 0)\n        \n    return(X_TRAIN, Y_TRAIN, Count_X, Count_Y)","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:42:52.631428Z","iopub.execute_input":"2025-03-24T16:42:52.631840Z","iopub.status.idle":"2025-03-24T16:42:52.640110Z","shell.execute_reply.started":"2025-03-24T16:42:52.631799Z","shell.execute_reply":"2025-03-24T16:42:52.638754Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SETTINGS","metadata":{}},{"cell_type":"code","source":"# CONFIGURATION DATA\n# CHOOSE THE STEP AND THE ECHEANCE\nEcheance_minute = 45\nStep_minute = 15\nPixel = 256\nrain_limit = 0","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:43:06.953311Z","iopub.execute_input":"2025-03-24T16:43:06.953661Z","iopub.status.idle":"2025-03-24T16:43:06.958158Z","shell.execute_reply.started":"2025-03-24T16:43:06.953631Z","shell.execute_reply":"2025-03-24T16:43:06.956912Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Step_data = 5  # step in the original data\nStep = Step_minute // Step_data\n# number of images to train and to predict\nPrediction = Echeance_minute // Step_minute\nEntrainement = Prediction + 3 \nTot = Entrainement + Prediction","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:43:22.802546Z","iopub.execute_input":"2025-03-24T16:43:22.802940Z","iopub.status.idle":"2025-03-24T16:43:22.808296Z","shell.execute_reply.started":"2025-03-24T16:43:22.802908Z","shell.execute_reply":"2025-03-24T16:43:22.807116Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# GLOBAL CODE FOR GIVEN THE DATASET TO LEARN THE MODEL\nmonth = [1, 2, 3]\npart = [1, 2, 3]\nyear = 2016","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:43:28.606393Z","iopub.execute_input":"2025-03-24T16:43:28.606780Z","iopub.status.idle":"2025-03-24T16:43:28.611600Z","shell.execute_reply.started":"2025-03-24T16:43:28.606746Z","shell.execute_reply":"2025-03-24T16:43:28.610458Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PREPARE TRAIN DATA","metadata":{}},{"cell_type":"code","source":"## LOOP FOR TRAIN DATA\ninit = 0\nfor m in month:\n    for p in part:\n        pickle = load_fichier(year, p, m)\n        print(\"This is the part \" ,p)\n    \n        if pickle[\"miss_dates\"].shape[0] == 0:\n            print(\"There is no missing data in this chunk\")\n            data_radar,dates_radar = cut_timestep(pickle, Step_minute)\n            print(data_radar.shape)\n            data_cut = cut_data_and_coord(data_radar, Pixel, lat, lon)\n            print( data_cut.shape)            \n            X_TRAIN, Y_TRAIN = XYTRAIN(data_cut)\n            print(\"Shape of the temporary train data\", X_TRAIN.shape, Y_TRAIN.shape)\n        \n        else:\n            print(\"There is miss dates\")\n            data_radar,dates_radar = cut_timestep_miss2(pickle, Echeance_minute, Step_minute)\n            print(data_radar.shape)\n            data_cut = cut_data_and_coord(data_radar, Pixel, lat, lon)\n            print(data_cut.shape)            \n            X_TRAIN, Y_TRAIN = XYTRAIN(data_cut)\n            print(\"Shape of the temporary train data\", X_TRAIN.shape, Y_TRAIN.shape)\n        \n        if (init == 0):\n            X_TEMP = X_TRAIN\n            Y_TEMP = Y_TRAIN\n            print(\"STEP N°1: \", X_TEMP.shape, Y_TEMP.shape)\n        elif ( init == 1):\n            X_train = np.append(X_TEMP, X_TRAIN, axis = 0)\n            Y_train = np.append(Y_TEMP, Y_TRAIN, axis = 0)\n            print(\"STEP N°2: \",X_train.shape,Y_train.shape)\n        else:\n            X_train = np.append(X_train, X_TRAIN,axis = 0)\n            Y_train = np.append(Y_train, Y_TRAIN,axis = 0)\n            print(\"OTHER STEP : \", X_train.shape, Y_train.shape)\n        init += 1\n        print(\"----------------------------------------------------------------------\")\n        \nprint('End of Train')\ndel(X_TEMP, Y_TEMP, X_TRAIN, Y_TRAIN, data_cut, data_radar)","metadata":{"execution":{"iopub.status.busy":"2025-03-24T16:43:37.144211Z","iopub.execute_input":"2025-03-24T16:43:37.144583Z","iopub.status.idle":"2025-03-24T16:47:09.955783Z","shell.execute_reply.started":"2025-03-24T16:43:37.144552Z","shell.execute_reply":"2025-03-24T16:47:09.953961Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TRAIN ONLY ON IMAGE SEQUENCES WITH RAINS\nX_train, Y_train, Count_X, Count_Y = COUNT_RAIN_SITUATION(X_train, Y_train, rain_limit)\nprint(X_train.shape, Y_train.shape, Count_X, Count_Y)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:16:04.287840Z","iopub.execute_input":"2025-03-24T17:16:04.288986Z","iopub.status.idle":"2025-03-24T17:16:06.403105Z","shell.execute_reply.started":"2025-03-24T17:16:04.288886Z","shell.execute_reply":"2025-03-24T17:16:06.401915Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We make only 1 image prediction at one time\nY_train1 = Y_train[:, :, :, 0:1]","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:16:12.069288Z","iopub.execute_input":"2025-03-24T17:16:12.069660Z","iopub.status.idle":"2025-03-24T17:16:12.074607Z","shell.execute_reply.started":"2025-03-24T17:16:12.069620Z","shell.execute_reply":"2025-03-24T17:16:12.073348Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# U_NET NETWORKS","metadata":{}},{"cell_type":"code","source":"class LRA(keras.callbacks.Callback):\n    def __init__(self, model, initial_learning_rate, gamma, power):\n        super(LRA, self).__init__()\n        self.initial_learning_rate = initial_learning_rate\n        self.gamma = gamma\n        self.power = power\n        self.model = model # model is your compiled model\n    def on_train_begin(self, logs=None):\n        tf.keras.backend.set_value(self.model.optimizer.lr, self.initial_learning_rate)\n    \n    def on_train_batch_end(self, batch, logs = None):\n        lr = self.initial_learning_rate * tf.pow(gamma, batch * self.power)\n        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n        print('for ', batch, ' lr set to ', lr) ","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:16:26.364360Z","iopub.execute_input":"2025-03-24T17:16:26.364773Z","iopub.status.idle":"2025-03-24T17:16:26.375347Z","shell.execute_reply.started":"2025-03-24T17:16:26.364731Z","shell.execute_reply":"2025-03-24T17:16:26.374230Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"initial_learning_rate = 0.0005\ngamma = 0.98\npower = 1/2085","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:16:29.774899Z","iopub.execute_input":"2025-03-24T17:16:29.775264Z","iopub.status.idle":"2025-03-24T17:16:29.779888Z","shell.execute_reply.started":"2025-03-24T17:16:29.775228Z","shell.execute_reply":"2025-03-24T17:16:29.778917Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## MODEL 1","metadata":{}},{"cell_type":"code","source":"inputs = keras.Input(shape = (Pixel, Pixel, Entrainement))\n\nconv1 = layers.Conv2D(filters = 32, kernel_size = (3,3), activation = \"relu\", padding = \"same\")(inputs)\nconv1 = layers.Conv2D(filters = 32, kernel_size = (3,3), activation = \"relu\", padding = \"same\")(conv1)\n\nmaxpool1 = layers.MaxPooling2D(pool_size = (2, 2))(conv1)\n\nconv2 = layers.Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\", padding=\"same\")(maxpool1)\nconv2 = layers.Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\", padding=\"same\")(conv2)\n\nmaxpool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n\nconv3 = layers.Conv2D(filters=128,kernel_size=(3,3),activation=\"relu\", padding=\"same\")(maxpool2)\nconv3 = layers.Conv2D(filters=128,kernel_size=(3,3),activation=\"relu\", padding=\"same\")(conv3)\n\nmaxpool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n\nconv4 = layers.Conv2D(filters=256,kernel_size=(3,3),activation=\"relu\", padding=\"same\")(maxpool3)\nconv4 = layers.Conv2D(filters=256,kernel_size=(3,3),activation=\"relu\", padding=\"same\")(conv4)\ndrop4 = layers.Dropout(0.5)(conv4)\n\nmaxpool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n\nconv5 = layers.Conv2D(filters=512,kernel_size=(3,3),activation=\"relu\", padding=\"same\")(maxpool4)\nconv5 = layers.Conv2D(filters=512,kernel_size=(3,3),activation=\"relu\", padding=\"same\")(conv5)\ndrop5 = layers.Dropout(0.5)(conv5)\n\n\nup6 = layers.Conv2D(256, 2, activation = 'relu', padding=\"same\")(layers.UpSampling2D(size = (2,2))(drop5))\nmerge6 = layers.concatenate([drop4, up6], axis = 3)\n\nconv6 = layers.Conv2D(256, 3, activation = 'relu', padding=\"same\")(merge6)\nconv6 = layers.Conv2D(256, 3, activation = 'relu', padding=\"same\")(conv6)\n\n\n\nup7 = layers.Conv2D(128, 2, activation = 'relu', padding=\"same\")(layers.UpSampling2D(size = (2,2))(conv6))\nmerge7 = layers.concatenate([conv3, up7], axis = 3)\nconv7 = layers.Conv2D(128, 3, activation = 'relu', padding=\"same\")(merge7)\nconv7 = layers.Conv2D(128, 3, activation = 'relu', padding=\"same\")(conv7)\n\n\n\nup8 = layers.Conv2D(64, 2, activation = 'relu', padding=\"same\")(layers.UpSampling2D(size = (2,2))(conv7))\nmerge8 = layers.concatenate([conv2, up8], axis = 3)\nconv8 = layers.Conv2D(64, 3, activation = 'relu', padding=\"same\")(merge8)\nconv8 = layers.Conv2D(64, 3, activation = 'relu', padding=\"same\")(conv8)\n\nup9 = layers.Conv2D(32, 2, activation = 'relu', padding=\"same\")(layers.UpSampling2D(size = (2,2))(conv8))\nmerge9 = layers.concatenate([conv1,up9], axis = 3)\nconv9 = layers.Conv2D(32, 3, activation = 'relu', padding=\"same\")(merge9)\nconv9 = layers.Conv2D(32, 3, activation = 'relu' , padding=\"same\")(conv9)\n\n\nconv10 = layers.Conv2D(1, 3, activation = 'relu', padding=\"same\")(conv9)\n\n\nmodel1 = keras.Model(inputs, conv10)\n#adam1 = keras.optimizers.Adam(lr = 0.0005)\nmodel1.compile(optimizer = 'Adam', loss = 'mae', metrics = ['mae'])\nmodel1.summary()","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:16:36.160638Z","iopub.execute_input":"2025-03-24T17:16:36.161013Z","iopub.status.idle":"2025-03-24T17:16:36.796862Z","shell.execute_reply.started":"2025-03-24T17:16:36.160981Z","shell.execute_reply":"2025-03-24T17:16:36.795847Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N_epochs = 10\nmy_callbacks = [LRA(model=model1, initial_learning_rate = initial_learning_rate, gamma = gamma, power = power)] \nhistory1 = model1.fit(X_train, Y_train1, batch_size = 32, epochs = N_epochs, callbacks = my_callbacks)","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:16:43.489668Z","iopub.execute_input":"2025-03-24T17:16:43.490075Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SAVE MODEL\nmodel1.save(os.path.join(directory_save, 'saved_model', 'model_1'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## MODEL 2","metadata":{}},{"cell_type":"code","source":"filter_size = 8\nkernel_size = 5\npool_size = 2\n\nactiv = layers.ReLU(threshold = 1)\ninputs = keras.Input(shape=(Pixel, Pixel, Entrainement))  # 5 images en entrée\n\nconv1 = layers.Conv2D(filters = 2 * filter_size, kernel_size = kernel_size, padding = \"same\")(inputs)\nconv1 = activ(conv1)\nconv1 = layers.Conv2D(filters = 2 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv1)\nconv1 = activ(conv1)\nconv1 = layers.Conv2D(filters = 2 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv1)\nconv1 = activ(conv1)\n\nmaxpool1 = layers.MaxPooling2D(pool_size = pool_size)(conv1)\n\nconv2 = layers.Conv2D(filters = 4 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(maxpool1)\nconv2 = layers.Conv2D(filters = 4 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(conv2)\nconv2 = layers.Conv2D(filters = 4 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(conv2)\n\nmaxpool2 = layers.MaxPooling2D(pool_size = pool_size)(conv2)\n\nconv3 = layers.Conv2D(filters = 8 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(maxpool2)\nconv3 = layers.Conv2D(filters = 8 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(conv3)\nconv3 = layers.Conv2D(filters = 8 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(conv3)\n\nmaxpool3 = layers.MaxPooling2D(pool_size = pool_size)(conv3)\n\nconv4 = layers.Conv2D(filters = 16 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(maxpool3)\nconv4 = layers.Conv2D(filters = 16 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(conv4)\nconv4 = layers.Conv2D(filters = 16 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(conv4)\n\ndrop4 = layers.Dropout(0.5)(conv4)\n\nmaxpool4 = layers.MaxPooling2D(pool_size = pool_size)(conv4)\n\nconv5 = layers.Conv2D(filters = 32 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(maxpool4)\nconv5 = layers.Conv2D(filters = 32 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(conv5)\nconv5 = layers.Conv2D(filters = 32 * filter_size, kernel_size = kernel_size, activation = \"relu\", padding = \"same\")(conv5)\n\ndrop5 = layers.Dropout(0.5)(conv5)\n\n\nup6 = layers.Conv2D(16 * filter_size, 2, activation = 'relu', padding=\"same\")(layers.UpSampling2D(size = (2,2))(drop5))\nmerge6 = layers.concatenate([drop4, up6], axis = 3)\n\nconv6 = layers.Conv2D(16 * filter_size, 3, activation = 'relu', padding=\"same\")(merge6)\nconv6 = layers.Conv2D(16 * filter_size, 3, activation = 'relu', padding=\"same\")(conv6)\nconv6 = layers.Conv2D(16 * filter_size, 3, activation = 'relu', padding=\"same\")(conv6)\n\n\nup7 = layers.Conv2D(8 * filter_size, 2, activation = 'relu', padding=\"same\")(layers.UpSampling2D(size = (2,2))(conv6))\nmerge7 = layers.concatenate([conv3, up7], axis = 3)\nconv7 = layers.Conv2D(8 * filter_size, 3, activation = 'relu', padding=\"same\")(merge7)\nconv7 = layers.Conv2D(8 * filter_size, 3, activation = 'relu', padding=\"same\")(conv7)\nconv7 = layers.Conv2D(8 * filter_size, 3, activation = 'relu', padding=\"same\")(conv7)\n\n\nup8 = layers.Conv2D(4* filter_size, 2, activation = 'relu', padding=\"same\")(layers.UpSampling2D(size = (2,2))(conv7))\nmerge8 = layers.concatenate([conv2, up8], axis = 3)\nconv8 = layers.Conv2D(4 * filter_size, 3, activation = 'relu', padding=\"same\")(merge8)\nconv8 = layers.Conv2D(4 * filter_size, 3, activation = 'relu', padding=\"same\")(conv8)\nconv8 = layers.Conv2D(4 * filter_size, 3, activation = 'relu', padding=\"same\")(conv8)\n\nup9 = layers.Conv2D(2 * filter_size, 2, activation = 'relu', padding=\"same\")(layers.UpSampling2D(size = (2,2))(conv8))\nmerge9 = layers.concatenate([conv1, up9], axis = 3)\nconv9 = layers.Conv2D(2 * filter_size, 3, activation = 'relu', padding=\"same\")(merge9)\nconv9 = layers.Conv2D(2 * filter_size, 3, activation = 'relu' , padding=\"same\")(conv9)\nconv9 = layers.Conv2D(2 * filter_size, 3, activation = 'relu' , padding=\"same\")(conv9)\n\n # 'Prediction' images en sortie, avec une activation Sigmoid pour sortir une proba\n#conv10 = layers.Conv2D(Prediction, 3, activation = 'relu', padding=\"same\")(conv9)  \nconv10 = layers.Conv2D(1, 3, activation = 'relu', padding=\"same\")(conv9)  # 1 seule prédiction\n\nmodel2 = keras.Model(inputs, conv10)\nmodel2.compile(optimizer = \"Adam\", loss = 'mae', metrics = ['mae'])\nmodel2.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N_epochs = 10\nmy_callbacks = [LRA(model = model2, initial_learning_rate = initial_learning_rate, gamma = gamma, power = power)] \nhistory2 = model2.fit(X_train, Y_train1, batch_size = 32, epochs = N_epochs, callbacks = my_callbacks)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SAVE MODEL\nmodel2.save(os.path.join(directory_save, 'saved_model', 'model_2'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MODEL 3","metadata":{}},{"cell_type":"code","source":"filter_size = 8\nkernel_size = 5\npool_size = 2\n\nactiv = layers.ReLU(threshold = 1)\ninputs = keras.Input(shape=(Pixel, Pixel, Entrainement))  # 5 images en entrée\n\nconv1 = layers.Conv2D(filters = 2 * filter_size, kernel_size = kernel_size, padding = \"same\")(inputs)\nconv1 = activ(conv1)\nconv1 = layers.Conv2D(filters = 2 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv1)\nconv1 = activ(conv1)\nconv1 = layers.Conv2D(filters = 2 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv1)\nconv1 = activ(conv1)\n\nmaxpool1 = layers.MaxPooling2D(pool_size = pool_size)(conv1)\n\nconv2 = layers.Conv2D(filters = 4 * filter_size, kernel_size = kernel_size, padding = \"same\")(maxpool1)\nconv2 = activ(conv2)\nconv2 = layers.Conv2D(filters = 4 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv2)\nconv2 = activ(conv2)\nconv2 = layers.Conv2D(filters = 4 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv2)\nconv2 = activ(conv2)\n\nmaxpool2 = layers.MaxPooling2D(pool_size = pool_size)(conv2)\n\nconv3 = layers.Conv2D(filters = 8 * filter_size, kernel_size = kernel_size, padding = \"same\")(maxpool2)\nconv3 = activ(conv3)\nconv3 = layers.Conv2D(filters = 8 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv3)\nconv3 = activ(conv3)\nconv3 = layers.Conv2D(filters = 8 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv3)\nconv3 = activ(conv3)\n\nmaxpool3 = layers.MaxPooling2D(pool_size = pool_size)(conv3)\n\nconv4 = layers.Conv2D(filters = 16 * filter_size, kernel_size = kernel_size, padding = \"same\")(maxpool3)\nconv4 = activ(conv4)\nconv4 = layers.Conv2D(filters = 16 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv4)\nconv4 = activ(conv4)\nconv4 = layers.Conv2D(filters = 16 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv4)\nconv4 = activ(conv4)\n\ndrop4 = layers.Dropout(0.5)(conv4)\n\nmaxpool4 = layers.MaxPooling2D(pool_size = pool_size)(conv4)\n\nconv5 = layers.Conv2D(filters = 32 * filter_size, kernel_size = kernel_size, padding = \"same\")(maxpool4)\nconv5 = activ(conv5)\nconv5 = layers.Conv2D(filters = 32 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv5)\nconv5 = activ(conv5)\nconv5 = layers.Conv2D(filters = 32 * filter_size, kernel_size = kernel_size, padding = \"same\")(conv5)\nconv5 = activ(conv5)\n\n\ndrop5 = layers.Dropout(0.5)(conv5)\n\n\nup6 = layers.Conv2D(16 * filter_size, 2, padding=\"same\")(layers.UpSampling2D(size = (2,2))(drop5))\nup6 = activ(up6)\nmerge6 = layers.concatenate([drop4, up6], axis = 3)\n\nconv6 = layers.Conv2D(16 * filter_size, 3, padding=\"same\")(merge6)\nconv6 = activ(conv6)\nconv6 = layers.Conv2D(16 * filter_size, 3, padding=\"same\")(conv6)\nconv6 = activ(conv6)\nconv6 = layers.Conv2D(16 * filter_size, 3, padding=\"same\")(conv6)\nconv6 = activ(conv6)\n\nup7 = layers.Conv2D(8 * filter_size, 2, padding=\"same\")(layers.UpSampling2D(size = (2,2))(conv6))\nup7 = activ(up7)\nmerge7 = layers.concatenate([conv3, up7], axis = 3)\nconv7 = layers.Conv2D(8 * filter_size, 3, padding=\"same\")(merge7)\nconv7 = activ(conv7)\nconv7 = layers.Conv2D(8 * filter_size, 3, padding=\"same\")(conv7)\nconv7 = activ(conv7)\nconv7 = layers.Conv2D(8 * filter_size, 3, padding=\"same\")(conv7)\nconv7 = activ(conv7)\n\nup8 = layers.Conv2D(4* filter_size, 2, padding=\"same\")(layers.UpSampling2D(size = (2,2))(conv7))\nup8 = activ(up8)\nmerge8 = layers.concatenate([conv2, up8], axis = 3)\nconv8 = layers.Conv2D(4 * filter_size, 3, padding=\"same\")(merge8)\nconv8 = activ(conv8)\nconv8 = layers.Conv2D(4 * filter_size, 3, padding=\"same\")(conv8)\nconv8 = activ(conv8)\nconv8 = layers.Conv2D(4 * filter_size, 3, padding=\"same\")(conv8)\nconv8 = activ(conv8)\n\n\nup9 = layers.Conv2D(2 * filter_size, 2, padding=\"same\")(layers.UpSampling2D(size = (2,2))(conv8))\nup9 = activ(up9)\nmerge9 = layers.concatenate([conv1, up9], axis = 3)\nconv9 = layers.Conv2D(2 * filter_size, 3, padding=\"same\")(merge9)\nconv9 = activ(conv9)\nconv9 = layers.Conv2D(2 * filter_size, 3, padding=\"same\")(conv9)\nconv9 = activ(conv9)\nconv9 = layers.Conv2D(2 * filter_size, 3, padding=\"same\")(conv9)\nconv9 = activ(conv9)\n\n # 'Prediction' images en sortie, avec une activation Sigmoid pour sortir une proba\n#conv10 = layers.Conv2D(Prediction, 3, activation = 'relu', padding=\"same\")(conv9)  \nconv10 = layers.Conv2D(1, 3, padding=\"same\")(conv9)  # 1 seule prédiction\nconv10 = activ(conv10)\n\nmodel3 = keras.Model(inputs, conv10)\nmodel3.compile(optimizer = \"Adam\", loss = 'mae', metrics = ['mae'])\nmodel3.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N_epochs = 10\nmy_callbacks =[LRA(model = model3, initial_learning_rate = initial_learning_rate, gamma = gamma, power = power)] \nhistory3 = model3.fit(X_train, Y_train1, batch_size = 32, epochs = N_epochs, callbacks = my_callbacks)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SAVE MODEL\nmodel3.save(os.path.join(directory_save, 'saved_model', 'model_3'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PLOT THE RESULTS","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epoch = list(range(1, N_epochs + 1))\n\ndef plot_history(history):\n    fig, ax = plt.subplots()\n    ax.plot(epoch, history.history['loss'], 'o-', label = \"loss-mae\")\n    ax.set_xlabel(\"Epochs\")\n    ax.set_ylabel(\"mae loss\")\n    ax.legend()\n    ax.set_title('Loss plot for epoch iteration')\n    #plt.savefig(\"Loss_Train\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_history(history1)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_history(history2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_history(history3)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PREPARE TEST DATA","metadata":{}},{"cell_type":"code","source":"## LOOP FOR TEST DATA\ninit = 0\nfor p in part_test:\n    pickle_f = load_fichier(year_test,p,1)\n    print(\"This is the part \" ,p)\n    \n    if pickle_f[\"miss_dates\"].shape[0] == 0:\n        print(\"There is no missing data in this chunk\")\n        data_radar, dates_radar = cut_timestep(pickle_f, Step_minute)\n        print(data_radar.shape)\n        data_cut = cut_data_and_coord(data_radar, Pixel, lat, lon)\n        print( data_cut.shape) \n        X_TEST,Y_TEST = XYTRAIN(data_cut)\n        print(\"Shape of the temporary train data\", X_TEST.shape, Y_TEST.shape)     \n        \n    else:\n        print(\"There is miss dates\")\n        data_radar,dates_radar = cut_timestep_miss2(pickle_f, Echeance_minute, Step_minute)\n        print(data_radar.shape)\n        data_cut = cut_data_and_coord(data_radar, Pixel, lat, lon)\n        print(data_cut.shape)\n        X_TEST, Y_TEST = XYTRAIN(data_cut)\n        print(\"Shape of the temporary train data\", X_TEST.shape, Y_TEST.shape)   \n        \n    if (init == 0):\n        X_TEMP = X_TEST\n        Y_TEMP = Y_TEST\n        print(\"STEP N°1: \", X_TEMP.shape, Y_TEMP.shape)\n    elif ( init == 1):\n        X_test = np.append(X_TEMP, X_TEST, axis = 0)\n        Y_test = np.append(Y_TEMP, Y_TEST, axis = 0)\n        print(\"STEP N°2: \", X_test.shape, Y_test.shape)\n    else:\n        X_test = np.append(X_test, X_TEST, axis = 0)\n        Y_test = np.append(Y_test, Y_TEST, axis = 0)\n        print(\"OTHER STEP : \", X_test.shape, Y_test.shape)\n    init += 1\n    print(\"----------------------------------------------------------------------\")\n\nprint(\"End of Test\")\ndel(X_TEST, Y_TEST, data_cut, data_radar) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# VARIABLE FOR TEST DATA\nyear_test = 2018\nmonth_test = [1]\npart_test = [1, 2]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MODEL EVALUATION","metadata":{}},{"cell_type":"code","source":"Y_predict_models = ['','','']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def model_evaluate(model_n):\n    for k in range(3): # we will predict 3 images  \n        Y_test_k = Y_test[:, :, :, k : k + 1]  # predict only 1 image at one time\n        if k > 0:\n            X_test_k = X_test_k[:, :, :, 1:]\n            # remove first input image and add the previous predict image at the end of the input\n            X_test_k = np.concatenate([X_test_k, Y_predict_k[:, :, :, 0:]], -1) \n        else:\n            X_test_k = X_test[:, :, :, :]    \n    \n        results = model_n.evaluate(X_test_k, Y_test_k, batch_size = 20)    \n        print(\"test loss, test acc:\", results)    \n    \n        Y_predict_k = model_n.predict(X_test_k)  \n   \n        if k > 0:\n            Y_predict_tot = np.concatenate([Y_predict_tot, Y_predict_k], -1)\n        else:\n            Y_predict_tot = Y_predict_k[:, :, :, :] \n    \n    return Y_predict_tot","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MODEL 1\n\nY_predict_models[0] = model_evaluate(model1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MODEL 2\n\nY_predict_models[1] = model_evaluate(model2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MODEL 3\n\nY_predict_models[2] = model_evaluate(model3)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SAVE Test and Predictions\n#np.savez(os.path.join(directory_save, 'np_xtest_ytest_ypredictmodels'), X_test = X_test, Y_test = Y_test, Y_predict_models = Y_predict_models)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MAP PREDICTIONS VISUALIZATIONS","metadata":{}},{"cell_type":"code","source":"def LATLON_CUT(lat,lon):\n    lat_edge = 49.5\n    lon_edge = -2.5\n    lat_only = lat[:,1]\n    lon_only = lon[1,:]\n    Temp_lat = np.where(lat_only < lat_edge)\n    Temp_lon = np.where(lon_only < lon_edge)\n    Lat_cut_index = Temp_lat[0][:Pixel]\n    Lon_cut_index = Temp_lon[0][:Pixel]\n    lat_format= lat[Lat_cut_index, Lon_cut_index]\n    lon_format= lon[Lat_cut_index, Lon_cut_index]\n    return lat_format, lon_format","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lat/Lon formating for plot.\nlat_format, lon_format = LATLON_CUT(lat, lon)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cartopy.crs as ccrs\nfrom cartopy.mpl.geoaxes import GeoAxes\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import AxesGrid\nfrom matplotlib import colors\nimport cartopy.feature as cfeature\nimport numpy as np","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lllat = lat_format[-1]  #lower left latitude\nurlat = lat_format[0]  #upper right latitude\nlllon =  lon_format[0]  #lower left longitude\nurlon =lon_format[-1]  #upper right longitude\nextent = [lllon, urlon, lllat, urlat]\n\n# Choose the colormap\ncmap = colors.ListedColormap(['silver','white', 'darkslateblue', 'mediumblue','dodgerblue', \n                              'skyblue','olive','mediumseagreen','cyan','lime','yellow',\n                              'khaki','burlywood','orange','brown','pink','red','plum'])\nbounds = [-1, 0, 2, 4, 6, 8, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 75]\nnorm = colors.BoundaryNorm(bounds, cmap.N)\n\n\ndef map_predict(model_n, sequence):\n    lats, lons = np.meshgrid(lat_format, lon_format)\n    projection = ccrs.PlateCarree()\n    axes_class = (GeoAxes, dict(map_projection = projection))\n    fig = plt.figure(figsize = (80, 80))\n    axgr = AxesGrid(fig, 222, axes_class = axes_class,\n                    nrows_ncols = (2, 9),\n                    axes_pad = 0.4,\n                    cbar_location ='right',\n                    cbar_mode = 'single',\n                    cbar_size = '5%',\n                    label_mode = '')\n                   # shared_all=True)  # note the empty label_mode\n    \n    for i, ax in enumerate(axgr):\n        ax.coastlines(resolution = '50m', linewidth = 2)\n        ax.gridlines()\n        ax.add_feature(cfeature.BORDERS.with_scale('50m'))\n        if i < 6:\n            p = ax.imshow(X_test[sequence, :, :, i], cmap=cmap, norm=norm, interpolation='none', origin='upper', extent=extent)\n            ax.set_title('t - {} min'.format(75 - 15 * i))\n        elif i >= 6 and i < 9:\n            p = ax.imshow(Y_test[sequence, :, :, i - 6], cmap=cmap, norm=norm, interpolation='none', origin='upper', extent=extent)\n            ax.set_title('truth : t + {} min'.format(15 * (i - 5)))\n        elif i >= 9 and i < 15:\n            p = ax.imshow(X_test[sequence, :, :, i - 9], cmap=cmap, norm=norm, interpolation='none', origin='upper', extent=extent)\n        elif i >=15 and i < 19:\n            p =  ax.imshow(model_n[sequence, :, :, i - 15], cmap=cmap, norm=norm, interpolation='none', origin='upper', extent=extent)\n            ax.set_title('predict : t + {} min'.format(15 * (i - 14)))\n    plt.colorbar(p, cmap=cmap, norm=norm, boundaries=bounds, ticks=bounds, cax=axgr.cbar_axes[0]).set_label('Rainfall (in 1/100 mm) / -1 : missing values')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## MODEL 1","metadata":{}},{"cell_type":"code","source":"map_predict(Y_predict_models[0], 92)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## MODEL 2","metadata":{}},{"cell_type":"code","source":"map_predict(Y_predict_models[1], 92)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## MODEL 3","metadata":{}},{"cell_type":"code","source":"map_predict(Y_predict_models[2], 92)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ALL THE MODELS","metadata":{}},{"cell_type":"code","source":"lllat = lat_format[-1]  #lower left latitude\nurlat = lat_format[0]  #upper right latitude\nlllon =  lon_format[0]  #lower left longitude\nurlon =lon_format[-1]  #upper right longitude\nextent = [lllon, urlon, lllat, urlat]\n\n# Choose the colormap\ncmap = colors.ListedColormap(['silver','white', 'darkslateblue', 'mediumblue','dodgerblue', \n                              'skyblue','olive','mediumseagreen','cyan','lime','yellow',\n                              'khaki','burlywood','orange','brown','pink','red','plum'])\nbounds = [-1, 0, 2, 4, 6, 8, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 75]\nnorm = colors.BoundaryNorm(bounds, cmap.N)\n\nlats, lons = np.meshgrid(lat_format, lon_format)\n\nprojection = ccrs.PlateCarree()\naxes_class = (GeoAxes, dict(map_projection = projection))\n\nfig = plt.figure(figsize = (80, 80))\n\naxgr = AxesGrid(fig, 222, axes_class = axes_class,\n                    nrows_ncols = (4, 9),\n                    axes_pad = 0.4,\n                    cbar_location ='right',\n                    cbar_mode = 'single',\n                    cbar_size = '5%',\n                    label_mode = '')\n                   # shared_all=True)  # note the empty label_mode\n\n\nsequence = 92\nfor i, ax in enumerate(axgr):    \n    ax.coastlines(resolution = '50m', linewidth = 2)\n    ax.gridlines()\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'))\n\n    if i % 9 < 6:\n        p = ax.imshow(X_test[sequence, :, :, i % 9], cmap = cmap, norm = norm, interpolation = 'none', origin = 'upper', extent = extent)\n        if i // 9 == 0:\n            ax.set_title('t - {} min'.format(75 - 15 * i))\n    else:\n        if i // 9 == 0:\n            p = ax.imshow(Y_test[sequence, :, :, i - 6], cmap = cmap, norm = norm, interpolation = 'none', origin = 'upper', extent = extent)\n            ax.set_title('truth : t + {} min'.format(15 * (i - 5)))\n        else:\n            p =  ax.imshow(Y_predict_models[i//9 - 1][sequence, :, :, i % 9 - 6], cmap = cmap, norm = norm, interpolation = 'none', origin = 'upper', extent = extent)\n            ax.set_title('Model {} : t + {} min'.format(i // 9, 15 * (i % 9 - 5)))\n            \n     \n        \n         \n\nplt.colorbar(p, cmap=cmap, norm=norm, boundaries=bounds, ticks=bounds, cax=axgr.cbar_axes[0]).set_label('Rainfall (in 1/100 mm) / -1 : missing values')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}